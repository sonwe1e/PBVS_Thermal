# ===== 实验环境配置 =====
seed: 42  # 随机种子，用于确保实验的可重复性 
# exp_name: "v10+lkfb_attn_woact"  # 实验名称
exp_name: "v1_woattnffn_onlyblur"  # 实验名称
save_wandb: true  # 是否将训练过程的指标保存到 wandb
project: "ImageSuperResolution"  # wandb 项目名称

# ===== 数据集配置 =====
data_path: "/media/hdd/sonwe1e/Competition/ImageSuperResolution/DF2K"  # 数据集路径
num_workers: 8  # 用于数据加载的并行线程数
extra_data: ''

# ===== 模型配置 =====
resume: null

# ===== 模型配置 =====
upscaling_factor: 4
dim: 64
n_blocks: 6

# ===== 优化器配置 =====
learning_rate: 0.0008  # 学习率
pct_start: 0.06
weight_decay: 0.0005  # 权重衰减系数，用于防止过拟合
beta2: 0.95  # Adam 优化器的 beta2 参数

# ===== 训练配置 =====
batch_size: 84  # 批次大小
epochs: 500  # 训练的总轮数
devices: 
- 1
precision: "32"  # 训练使用的精度模式，常见选择包括 32，16，bf16-mixed
gradient_clip_val: 4.0  # 梯度裁剪的最大值，用于防止梯度爆炸，默认不使用
accumulate_grad_batches: 1  # 梯度累积的 batch 数，用于模拟更大的 batch size，默认不使用

# ===== 监控配置 =====
val_check: 1.0  # 验证集频率，当容易出现过拟合现象的时候可以设置较小的值找到比较好的 checkpoint
log_step: 50  # 日志记录的频率，例如每训练 log_step 个 batch 记录一次