{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tools.models.competition_backup import FusionNet\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "valid_transform = A.Compose([ToTensorV2()])\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "def compute_ssim(img1, img2):\n",
    "    \"\"\"\n",
    "    计算两幅灰度图像的 SSIM 指数\n",
    "    (输入图像应为相同尺寸的 numpy 数组，建议先转换为灰度图)\n",
    "    \"\"\"\n",
    "    # 检查图像尺寸是否相同\n",
    "    if img1.shape != img2.shape:\n",
    "        raise ValueError(\"Input images must have the same dimensions\")\n",
    "\n",
    "    # 转换为浮点数计算\n",
    "    img1 = img1.astype(np.float32)\n",
    "    img2 = img2.astype(np.float32)\n",
    "\n",
    "    # 常量参数 (基于 8-bit 图像动态范围 0-255)\n",
    "    C1 = (0.01 * 255) ** 2\n",
    "    C2 = (0.03 * 255) ** 2\n",
    "\n",
    "    # 高斯核参数\n",
    "    kernel_size = (11, 11)\n",
    "    sigma = 1.5\n",
    "\n",
    "    # 计算均值 (高斯模糊)\n",
    "    mu1 = cv2.GaussianBlur(img1, kernel_size, sigma)\n",
    "    mu2 = cv2.GaussianBlur(img2, kernel_size, sigma)\n",
    "\n",
    "    # 计算均值平方\n",
    "    mu1_sq = mu1**2\n",
    "    mu2_sq = mu2**2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    # 计算方差和协方差\n",
    "    sigma1_sq = cv2.GaussianBlur(img1**2, kernel_size, sigma) - mu1_sq\n",
    "    sigma2_sq = cv2.GaussianBlur(img2**2, kernel_size, sigma) - mu2_sq\n",
    "    sigma12 = cv2.GaussianBlur(img1 * img2, kernel_size, sigma) - mu1_mu2\n",
    "\n",
    "    # SSIM 计算\n",
    "    numerator = (2 * mu1_mu2 + C1) * (2 * sigma12 + C2)\n",
    "    denominator = (mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2)\n",
    "    ssim_map = numerator / denominator\n",
    "\n",
    "    return np.mean(ssim_map)\n",
    "\n",
    "\n",
    "def perform_inference(\n",
    "    config,\n",
    "    ckpt_path,\n",
    "    test_dir=\"/media/hdd/sonwe1e/Competition/PBVS_Thermal/Data/valid/CUBIC_x8\",\n",
    "    out_dir=None,\n",
    "    device=0,\n",
    "    num_ckpts=1,  # 新增参数：选择checkpoint的数量\n",
    "    select_by=\"max_loss\",  # 新增参数：选择方式（max_loss/min_loss）\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs inference with multiple checkpoints and TTA.\n",
    "\n",
    "    Args:\n",
    "        num_ckpts (int): Number of checkpoints to use (sorted by loss)\n",
    "        select_by (str): 'max_loss' or 'min_loss' to specify checkpoint selection\n",
    "    \"\"\"\n",
    "    if out_dir is None:\n",
    "        out_dir = os.path.join(os.path.dirname(test_dir), \"PRED\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # 1. 解析checkpoint文件 ------------------------------------------------\n",
    "    ckpt_files = [f for f in os.listdir(ckpt_path) if f.endswith(\".ckpt\")]\n",
    "\n",
    "    # 2. 加载多个模型 -----------------------------------------------------\n",
    "    models = []\n",
    "    for fname in ckpt_files:\n",
    "        model = FusionNet(\n",
    "            dim=config.dim,\n",
    "            n_blocks=config.n_blocks,\n",
    "            upscaling_factor=config.upscaling_factor,\n",
    "            fmb_params={\n",
    "                \"smfa_growth\": config.smfa_growth,\n",
    "                \"pcfn_growth\": config.pcfn_growth,\n",
    "                \"snfa_dropout\": config.snfa_dropout,\n",
    "                \"pcfn_dropout\": config.pcfn_dropout,\n",
    "                \"p_rate\": config.p_rate,\n",
    "            },\n",
    "        ).cuda(device)\n",
    "\n",
    "        # 加载checkpoint\n",
    "        ckpt = torch.load(\n",
    "            os.path.join(ckpt_path, fname),\n",
    "            map_location=f\"cuda:{device}\",\n",
    "            weights_only=False,\n",
    "        )[\"state_dict\"]\n",
    "\n",
    "        # 处理key\n",
    "        for k in list(ckpt.keys()):\n",
    "            if \"model\" not in k:\n",
    "                ckpt.pop(k)\n",
    "                continue\n",
    "            new_key = k.replace(\"model.\", \"\")\n",
    "            ckpt[new_key] = ckpt.pop(k)\n",
    "            if \"loss\" in new_key:\n",
    "                del ckpt[new_key]\n",
    "\n",
    "        model.load_state_dict(ckpt, strict=True)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "\n",
    "    # 3. 执行推理（多模型+多TTA）---------------------------------------------\n",
    "    for img_name in tqdm(os.listdir(test_dir)):\n",
    "        if not img_name.endswith(\".bmp\"):\n",
    "            continue\n",
    "\n",
    "        # 加载图像\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 预处理\n",
    "        orig = valid_transform(image=img)[\"image\"] / 127.5 - 1\n",
    "\n",
    "        # 创建四种TTA变换\n",
    "        images = [\n",
    "            orig,\n",
    "            torch.flip(orig, [2]),  # 水平翻转\n",
    "            torch.flip(orig, [1]),  # 垂直翻转\n",
    "            torch.flip(orig, [1, 2]),  # 水平+垂直翻转\n",
    "            torch.rot90(orig, 1, [1, 2]),  # 逆时针旋转90度\n",
    "            torch.rot90(orig, 2, [1, 2]),  # 逆时针旋转180度\n",
    "            torch.rot90(orig, 3, [1, 2]),  # 逆时针旋转270度\n",
    "        ]\n",
    "\n",
    "        all_preds = []\n",
    "        for model in models:\n",
    "            model_preds = []\n",
    "            for idx, inp in enumerate(images):\n",
    "                inp_tensor = inp.unsqueeze(0).cuda(device)\n",
    "                with torch.no_grad():\n",
    "                    output = model(inp_tensor)\n",
    "\n",
    "                # 逆变换\n",
    "                if idx == 1:\n",
    "                    output = torch.flip(output, [3])\n",
    "                elif idx == 2:\n",
    "                    output = torch.flip(output, [2])\n",
    "                elif idx == 3:\n",
    "                    output = torch.flip(output, [2, 3])\n",
    "                elif idx == 4:\n",
    "                    output = torch.rot90(output, 3, [2, 3])\n",
    "                elif idx == 5:\n",
    "                    output = torch.rot90(output, 2, [2, 3])\n",
    "                elif idx == 6:\n",
    "                    output = torch.rot90(output, 1, [2, 3])\n",
    "\n",
    "                model_preds.append(output)\n",
    "\n",
    "            # 单模型的多TTA平均\n",
    "            model_avg = torch.mean(torch.stack(model_preds), dim=0)\n",
    "            all_preds.append(model_avg)\n",
    "\n",
    "        # 多模型平均\n",
    "        final_pred = torch.mean(torch.stack(all_preds), dim=0)\n",
    "\n",
    "        # 后处理并保存\n",
    "        final_pred = final_pred.squeeze()\n",
    "        final_pred = (\n",
    "            (final_pred.permute(1, 2, 0).cpu().numpy() * 127.5 + 127.5)\n",
    "            .clip(0, 255)\n",
    "            .astype(\"uint8\")\n",
    "        )\n",
    "        cv2.imwrite(os.path.join(out_dir, img_name), final_pred)\n",
    "\n",
    "    # 4. 压缩结果 ---------------------------------------------------------\n",
    "    print(\"Zipping results...\")\n",
    "    zip_name = f\"PRED_{os.path.basename(ckpt_path)}_top{num_ckpts}_{select_by}.zip\"\n",
    "    os.system(f\"cd {out_dir} && zip '{os.path.join('../../../PBVS', zip_name)}' *.bmp\")\n",
    "    print(f\"Results saved to: {out_dir}\")\n",
    "    return out_dir\n",
    "\n",
    "\n",
    "def calculate_metrics(pred_dir, gt_dir):\n",
    "    \"\"\"\n",
    "    计算预测图像和真实图像之间的 PSNR, SSIM, RMSE 和 LPIPS。\n",
    "\n",
    "    Args:\n",
    "        pred_dir (str): 预测图像目录。\n",
    "        gt_dir (str): 真实图像目录。\n",
    "\n",
    "    Returns:\n",
    "        dict: 包含平均 PSNR, SSIM, RMSE 和 LPIPS 值的字典。\n",
    "    \"\"\"\n",
    "\n",
    "    pred_files = [f for f in os.listdir(pred_dir) if f.lower().endswith(\".bmp\")]\n",
    "    gt_files = [f for f in os.listdir(gt_dir) if f.lower().endswith(\".bmp\")]\n",
    "    common_files = sorted(\n",
    "        list(set(pred_files) & set(gt_files))\n",
    "    )  # Find common files and sort\n",
    "\n",
    "    if not common_files:\n",
    "        print(\"No common BMP files found between the two directories.\")\n",
    "        return None\n",
    "\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    rmse_values = []\n",
    "\n",
    "    for filename in common_files:\n",
    "        pred_path = os.path.join(pred_dir, filename)\n",
    "        gt_path = os.path.join(gt_dir, filename)\n",
    "\n",
    "        try:\n",
    "            pred_img = cv2.imread(pred_path, cv2.IMREAD_COLOR)\n",
    "            gt_img = cv2.imread(gt_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "            if pred_img is None or gt_img is None:\n",
    "                print(f\"Skipping {filename} due to read error.\")\n",
    "                continue\n",
    "\n",
    "            if pred_img.shape != gt_img.shape:\n",
    "                print(f\"Skipping {filename} due to the different image shape\")\n",
    "                continue\n",
    "\n",
    "            # Convert images to grayscale for SSIM (scikit-image's ssim expects grayscale)\n",
    "            pred_gray = cv2.cvtColor(pred_img, cv2.COLOR_BGR2GRAY)\n",
    "            gt_gray = cv2.cvtColor(gt_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Calculate PSNR\n",
    "            psnr_values.append(psnr(gt_img, pred_img, data_range=255))\n",
    "\n",
    "            # Calculate SSIM\n",
    "            ssim_values.append(compute_ssim(gt_gray, pred_gray))\n",
    "\n",
    "            # Calculate RMSE\n",
    "            rmse = np.sqrt(\n",
    "                np.mean(\n",
    "                    (\n",
    "                        gt_img.astype(np.float64) / 255.0\n",
    "                        - pred_img.astype(np.float64) / 255.0\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            )\n",
    "            rmse_values.append(rmse)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not psnr_values:  # Check if any images were successfully processed\n",
    "        print(\"No images were successfully processed.\")\n",
    "        return None\n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_psnr = np.mean(psnr_values)\n",
    "    avg_ssim = np.mean(ssim_values)\n",
    "    avg_rmse = np.mean(rmse_values)\n",
    "\n",
    "    return {\n",
    "        \"PSNR\": avg_psnr,\n",
    "        \"SSIM\": avg_ssim,\n",
    "        \"RMSE\": avg_rmse,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping results...\n",
      "updating: 001_01_D2_th.bmp (deflated 82%)\n",
      "updating: 002_01_D4_th.bmp (deflated 75%)\n",
      "updating: 002_02_D1_th.bmp (deflated 79%)\n",
      "updating: 004_02_D1_th.bmp (deflated 87%)\n",
      "updating: 006_01_D4_th.bmp (deflated 78%)\n",
      "updating: 008_01_D4_th.bmp (deflated 79%)\n",
      "updating: 009_01_D2_th.bmp (deflated 82%)\n",
      "updating: 009_02_D1_th.bmp (deflated 81%)\n",
      "updating: 013_02_D1_th.bmp (deflated 85%)\n",
      "updating: 014_01_D4_th.bmp (deflated 77%)\n",
      "updating: 015_01_D2_th.bmp (deflated 78%)\n",
      "updating: 016_02_D1_th.bmp (deflated 85%)\n",
      "updating: 017_02_D1_th.bmp (deflated 82%)\n",
      "updating: 019_01_D1_th.bmp (deflated 81%)\n",
      "updating: 021_01_D2_th.bmp (deflated 78%)\n",
      "updating: 026_01_D3_th.bmp (deflated 78%)\n",
      "updating: 026_02_D1_th.bmp (deflated 79%)\n",
      "updating: 027_01_D1_th.bmp (deflated 86%)\n",
      "updating: 031_02_D1_th.bmp (deflated 84%)\n",
      "updating: 034_01_D1_th.bmp (deflated 77%)\n",
      "Results saved to: /media/hdd/sonwe1e/Competition/PBVS_Thermal/Data/valid/PRED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/media/hdd/sonwe1e/Competition/PBVS_Thermal/Data/valid/PRED'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 示例配置\n",
    "class SMFANetConfig:\n",
    "    def __init__(self):\n",
    "        self.dim = 192\n",
    "        self.n_blocks = 12\n",
    "        self.pcfn_growth = 8\n",
    "        # self.dim = 96\n",
    "        # self.n_blocks = 8\n",
    "        # self.pcfn_growth = 4\n",
    "        self.upscaling_factor = 8\n",
    "        self.smfa_growth = 4\n",
    "        self.snfa_dropout = 0.0\n",
    "        self.pcfn_dropout = 0.12\n",
    "        self.p_rate = 0.25\n",
    "\n",
    "\n",
    "opt = SMFANetConfig()\n",
    "perform_inference(\n",
    "    opt,\n",
    "    ckpt_path=\"./checkpoints/selected\",\n",
    "    num_ckpts=10,  # 使用loss最大的2个checkpoint\n",
    "    select_by=\"max_loss\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics:\n",
      "PSNR: 27.5821  \n",
      "SSIM: 0.8348  \n",
      "RMSE: 0.0435  \n"
     ]
    }
   ],
   "source": [
    "pred_dir = \"/media/hdd/sonwe1e/Competition/PBVS_Thermal/Data/valid/PRED\"\n",
    "gt_dir = \"/media/hdd/sonwe1e/Competition/PBVS_Thermal/Data/valid/GT\"\n",
    "\n",
    "metrics = calculate_metrics(pred_dir, gt_dir)\n",
    "\n",
    "if metrics:\n",
    "    print(f\"Average Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value:.4f}  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  5.30it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.32it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.33it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.34it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.30it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.35it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.30it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.32it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.30it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.34it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PSNR      SSIM      RMSE                  checkpoint\n",
      "5   28.018966  0.840942  0.041430  epoch_231-loss_27.436.ckpt\n",
      "8   28.018497  0.840865  0.041426  epoch_228-loss_27.437.ckpt\n",
      "10  28.018215  0.840805  0.041431  epoch_234-loss_27.437.ckpt\n",
      "1   28.017602  0.840940  0.041433  epoch_235-loss_27.435.ckpt\n",
      "2   28.017575  0.840986  0.041432  epoch_230-loss_27.436.ckpt\n",
      "0   28.016079  0.840981  0.041438  epoch_237-loss_27.436.ckpt\n",
      "3   28.015831  0.840878  0.041439  epoch_238-loss_27.435.ckpt\n",
      "9   28.014337  0.840886  0.041447                   last.ckpt\n",
      "4   28.014337  0.840886  0.041447  epoch_249-loss_27.435.ckpt\n",
      "7   28.014334  0.841087  0.041449  epoch_226-loss_27.436.ckpt\n",
      "6   28.012695  0.840817  0.041454  epoch_241-loss_27.435.ckpt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_model(config, ckpt_file):\n",
    "    model = FusionNet(\n",
    "        dim=config.dim,\n",
    "        n_blocks=config.n_blocks,\n",
    "        upscaling_factor=config.upscaling_factor,\n",
    "        fmb_params={\n",
    "            \"smfa_growth\": config.smfa_growth,\n",
    "            \"pcfn_growth\": config.pcfn_growth,\n",
    "            \"snfa_dropout\": config.snfa_dropout,\n",
    "            \"pcfn_dropout\": config.pcfn_dropout,\n",
    "            \"p_rate\": config.p_rate,\n",
    "        },\n",
    "    ).cuda(0)\n",
    "    # 加载checkpoint\n",
    "    ckpt = torch.load(os.path.join(ckpt_file), map_location=\"cpu\", weights_only=False)[\n",
    "        \"state_dict\"\n",
    "    ]\n",
    "\n",
    "    # 处理key\n",
    "    for k in list(ckpt.keys()):\n",
    "        if \"model\" not in k:\n",
    "            ckpt.pop(k)\n",
    "            continue\n",
    "        new_key = k.replace(\"model.\", \"\")\n",
    "        ckpt[new_key] = ckpt.pop(k)\n",
    "        if \"loss\" in new_key:\n",
    "            del ckpt[new_key]\n",
    "\n",
    "    model.load_state_dict(ckpt, strict=True)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def infer_from_model(model, output_path):\n",
    "    test_dir = \"/media/hdd/sonwe1e/Competition/PBVS_Thermal/Data/valid/CUBIC_x8\"\n",
    "    out_dir = output_path\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for img_name in tqdm(os.listdir(test_dir)):\n",
    "        # 加载图像\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 预处理\n",
    "        orig = valid_transform(image=img)[\"image\"] / 127.5 - 1\n",
    "\n",
    "        # 创建四种TTA变换\n",
    "        images = [\n",
    "            orig,\n",
    "            torch.flip(orig, [2]),  # 水平翻转\n",
    "            torch.flip(orig, [1]),  # 垂直翻转\n",
    "            torch.flip(orig, [1, 2]),  # 水平+垂直翻转\n",
    "            torch.rot90(orig, 1, [1, 2]),  # 顺时针旋转90度\n",
    "            torch.rot90(orig, 2, [1, 2]),  # 顺时针旋转180度\n",
    "            torch.rot90(orig, 3, [1, 2]),  # 顺时针旋转270度\n",
    "        ]\n",
    "\n",
    "        all_preds = []\n",
    "        for idx, inp in enumerate(images):\n",
    "            inp_tensor = inp.unsqueeze(0).cuda(0)\n",
    "            with torch.no_grad():\n",
    "                output = model(inp_tensor)\n",
    "\n",
    "            # 逆变换\n",
    "            if idx == 1:\n",
    "                output = torch.flip(output, [3])\n",
    "            elif idx == 2:\n",
    "                output = torch.flip(output, [2])\n",
    "            elif idx == 3:\n",
    "                output = torch.flip(output, [2, 3])\n",
    "            elif idx == 4:\n",
    "                output = torch.rot90(output, 3, [2, 3])\n",
    "            elif idx == 5:\n",
    "                output = torch.rot90(output, 2, [2, 3])\n",
    "            elif idx == 6:\n",
    "                output = torch.rot90(output, 1, [2, 3])\n",
    "\n",
    "            all_preds.append(output)\n",
    "\n",
    "        # 多TTA平均\n",
    "        final_pred = torch.mean(torch.stack(all_preds), dim=0)\n",
    "\n",
    "        # 后处理并保存\n",
    "        final_pred = final_pred.squeeze()\n",
    "        final_pred = (\n",
    "            (final_pred.permute(1, 2, 0).cpu().numpy() * 127.5 + 127.5)\n",
    "            .clip(0, 255)\n",
    "            .astype(\"uint8\")\n",
    "        )\n",
    "        cv2.imwrite(os.path.join(out_dir, img_name), final_pred)\n",
    "\n",
    "\n",
    "def calculate_metrics(pred_dir, gt_dir):\n",
    "    \"\"\"\n",
    "    计算预测图像和真实图像之间的 PSNR, SSIM, RMSE 和 LPIPS。\n",
    "\n",
    "    Args:\n",
    "        pred_dir (str): 预测图像目录。\n",
    "        gt_dir (str): 真实图像目录。\n",
    "\n",
    "    Returns:\n",
    "        dict: 包含平均 PSNR, SSIM, RMSE 和 LPIPS 值的字典。\n",
    "    \"\"\"\n",
    "\n",
    "    pred_files = [f for f in os.listdir(pred_dir) if f.lower().endswith(\".bmp\")]\n",
    "    gt_files = [f for f in os.listdir(gt_dir) if f.lower().endswith(\".bmp\")]\n",
    "    common_files = sorted(\n",
    "        list(set(pred_files) & set(gt_files))\n",
    "    )  # Find common files and sort\n",
    "\n",
    "    if not common_files:\n",
    "        print(\"No common BMP files found between the two directories.\")\n",
    "        return None\n",
    "\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    rmse_values = []\n",
    "\n",
    "    for filename in common_files:\n",
    "        pred_path = os.path.join(pred_dir, filename)\n",
    "        gt_path = os.path.join(gt_dir, filename)\n",
    "\n",
    "        try:\n",
    "            pred_img = cv2.imread(pred_path, cv2.IMREAD_COLOR)\n",
    "            gt_img = cv2.imread(gt_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "            if pred_img is None or gt_img is None:\n",
    "                print(f\"Skipping {filename} due to read error.\")\n",
    "                continue\n",
    "\n",
    "            if pred_img.shape != gt_img.shape:\n",
    "                print(f\"Skipping {filename} due to the different image shape\")\n",
    "                continue\n",
    "\n",
    "            # Convert images to grayscale for SSIM (scikit-image's ssim expects grayscale)\n",
    "            pred_gray = cv2.cvtColor(pred_img, cv2.COLOR_BGR2GRAY)\n",
    "            gt_gray = cv2.cvtColor(gt_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Calculate PSNR\n",
    "            psnr_values.append(psnr(gt_img, pred_img, data_range=255))\n",
    "\n",
    "            # Calculate SSIM\n",
    "            ssim_values.append(compute_ssim(gt_gray, pred_gray))\n",
    "\n",
    "            # Calculate RMSE\n",
    "            rmse = np.sqrt(\n",
    "                np.mean(\n",
    "                    (\n",
    "                        gt_img.astype(np.float64) / 255.0\n",
    "                        - pred_img.astype(np.float64) / 255.0\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            )\n",
    "            rmse_values.append(rmse)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not psnr_values:  # Check if any images were successfully processed\n",
    "        print(\"No images were successfully processed.\")\n",
    "        return None\n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_psnr = np.mean(psnr_values)\n",
    "    avg_ssim = np.mean(ssim_values)\n",
    "    avg_rmse = np.mean(rmse_values)\n",
    "\n",
    "    return {\n",
    "        \"PSNR\": avg_psnr,\n",
    "        \"SSIM\": avg_ssim,\n",
    "        \"RMSE\": avg_rmse,\n",
    "    }\n",
    "\n",
    "\n",
    "class SMFANetConfig:\n",
    "    def __init__(self):\n",
    "        self.dim = 192\n",
    "        self.n_blocks = 12\n",
    "        self.pcfn_growth = 8\n",
    "        self.upscaling_factor = 8\n",
    "        self.smfa_growth = 4\n",
    "        self.snfa_dropout = 0.0\n",
    "        self.pcfn_dropout = 0.12\n",
    "        self.p_rate = 0.25\n",
    "\n",
    "\n",
    "opt = SMFANetConfig()\n",
    "\n",
    "ckpt_files = glob.glob(\"./checkpoints/v3_finetune_res_df2k_whatever/*.ckpt\")\n",
    "metrics_list = []\n",
    "\n",
    "for ckpt_file in ckpt_files:\n",
    "    if '_0.8' in ckpt_file:\n",
    "        continue\n",
    "    model = load_model(opt, ckpt_file)\n",
    "    infer_from_model(\n",
    "        model, \"/media/hdd/sonwe1e/Competition/PBVS_Thermal/Data/valid/PRED\"\n",
    "    )\n",
    "    metrics = calculate_metrics(\n",
    "        \"/media/hdd/sonwe1e/Competition/PBVS_Thermal/Data/valid/PRED\",\n",
    "        \"/media/hdd/sonwe1e/Competition/PBVS_Thermal/Data/valid/GT\",\n",
    "    )\n",
    "\n",
    "    if metrics:\n",
    "        metrics[\"checkpoint\"] = os.path.basename(ckpt_file)\n",
    "        metrics_list.append(metrics)\n",
    "    os.rename(\n",
    "        ckpt_file,\n",
    "        ckpt_file.split(\"ep\")[0]\n",
    "        + f\"{(metrics['PSNR'] - 20):.4f}_{metrics['SSIM']:.4f}.ckpt\",\n",
    "    )\n",
    "\n",
    "# Create DataFrame from metrics\n",
    "if metrics_list:\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    print(metrics_df.sort_values(by=\"PSNR\", ascending=False))  # Sort by PSNR descending\n",
    "else:\n",
    "    print(\"No valid metrics collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PSNR      SSIM      RMSE                 checkpoint\n",
      "1  27.411100  0.830310  0.044394  epoch_24-loss_26.104.ckpt\n",
      "2  27.390467  0.829999  0.044541  epoch_16-loss_26.039.ckpt\n",
      "0  27.364948  0.828297  0.044652  epoch_19-loss_26.020.ckpt\n",
      "3  27.345387  0.829629  0.044740  epoch_18-loss_26.002.ckpt\n"
     ]
    }
   ],
   "source": [
    "if metrics_list:\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    print(metrics_df.sort_values(by=\"PSNR\", ascending=False))  # Sort by PSNR descending\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
